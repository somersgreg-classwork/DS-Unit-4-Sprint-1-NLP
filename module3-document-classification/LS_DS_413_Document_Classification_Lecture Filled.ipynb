{"cells":[{"cell_type":"markdown","metadata":{"id":"ifTTjn64-Xzj"},"source":["Lambda School Data Science\n","\n","*Unit 4, Sprint 1, Module 3*\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"zcea63EK-Xzm"},"source":["# Document Classification (Prepare)\n","\n","Today's guided module project will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a [kaggle competition](https://www.kaggle.com/c/whiskey-201911/). We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n","\n","Today's all about having fun and practicing your skills. The competition will begin\n","\n","## Learning Objectives\n","* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n","* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n","* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy"]},{"cell_type":"markdown","metadata":{"id":"qQ1uu46njb_7"},"source":["## Challenge -- this afternoon's lab module assignment\n","\n","1. Join Lambda School's [Whisky Classification Kaggle Competition](https://www.kaggle.com/c/whiskey-201911/)\n","2. Download the data\n","3. Train a model & try: \n","    - Creating a Text Extraction & Classification Pipeline\n","    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n","    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores to specify parameters from each level in the nested pipeline. For example, `lsi__svd__n_components` specifies the parameter `n_components` inside the `svd` pipeline, which is nested inside the `lsi` pipeline\n","    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n","4. Make a submission to Kaggle "]},{"cell_type":"markdown","metadata":{"id":"UPytzJbH-Xzn"},"source":["# 1. Text Feature Extraction & Classification Pipelines (Learn)\n","<a id=\"p1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"HbT6ZBGm-Xzo"},"source":["## Overview\n","\n","Sklearn pipelines allow you to stitch together multiple components of a machine learning process. The idea is that you can pass your raw data and get predictions out of the pipeline. This ability to pass raw input and receive a prediction from a singular class makes pipelines well suited for production, because you can pickle a pipeline without worry about other data preprocessing steps. \n","\n","*Note:* Each time we call the pipeline during grid search, each component is fit again. The vectorizer (tf-idf) transforms our entire vocabulary during each cross-validation fold. That transformation adds significant run time to our grid search. There *might* be interactions between the vectorizer and our classifier, so we estimate their performance together in the code below. However, if your goal is to reduce run time, train your vectorizer separately (ie out of the grid-searched pipeline). "]},{"cell_type":"markdown","metadata":{"id":"1k_QCMx0aEBV"},"source":["##1.1 Prepare Colab notebook"]},{"cell_type":"markdown","metadata":{"id":"V1G5XOXgZ4Li"},"source":["###1.1.1 Get Spacy"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8079,"status":"ok","timestamp":1632938374205,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"11PvjAIsJnfY","outputId":"8630c5fa-01b0-4c14-de18-a90f45416785"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-03-22 21:17:38.565539: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n","2022-03-22 21:17:38.566284: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","ERROR: Invalid requirement: '#'\n"]}],"source":["# Locally (or on colab) let's use en_core_web_lg \n","!python -m spacy download en_core_web_md # Can do lg, takes awhile"]},{"cell_type":"markdown","metadata":{"id":"EDs9XrfWZ9r6"},"source":["###1.1.2 Restart runtime!"]},{"cell_type":"markdown","metadata":{"id":"FE0sQ55sGT2a"},"source":["###1.1.3 Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":838,"status":"ok","timestamp":1632938387294,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"Ra660bkI-Xzp"},"outputs":[],"source":["# Import Statements\n","import os\n","import re\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import spacy\n","\n","from sklearn.datasets import fetch_20newsgroups\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","from sklearn.pipeline import FeatureUnion, Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.decomposition import PCA, TruncatedSVD\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"1xuB-nPGJxyb"},"source":["### 1.1.4 Load spacy"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":14735,"status":"ok","timestamp":1632938404368,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"0lNTdQWqZxPU"},"outputs":[],"source":["# load in pre-trained w2v model \n","nlp = spacy.load(\"en_core_web_md\")"]},{"cell_type":"markdown","metadata":{"id":"u4bNGlpRzbK4"},"source":["##1.2 Example NLP document classification pipeline \n","Working with the `20newsgroups` data set available from `sklearn`, <br>we'll build a classifier that can classify news articles into 2 different categories."]},{"cell_type":"markdown","metadata":{"id":"eWAippd8321u"},"source":["### 1.2.1 Get the data set"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":461,"status":"ok","timestamp":1632938411924,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"18q4-_qs-Xzq","nbgrader":{"grade":false,"grade_id":"cell-2d860ec20fad5c0c","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# Dataset\n","from sklearn.datasets import fetch_20newsgroups\n","\n","# 2 categories to class today\n","categories = ['alt.atheism',\n","              'talk.religion.misc']\n","\n","data = fetch_20newsgroups(subset='all', \n","                          categories=categories)"]},{"cell_type":"markdown","metadata":{"id":"F58_GhV_NRfw"},"source":["#### 1.2.2 Examine and understand the data set!"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1632938419920,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"xmGX_qzFKmVn","outputId":"f0c6e7ad-f6db-434b-d617-72bbb671965e"},"outputs":[{"data":{"text/plain":["sklearn.utils.Bunch"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["type(data)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":218,"status":"ok","timestamp":1632938422409,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"5-ZR18fJKvx1","outputId":"80827ab1-7dd2-4d07-db99-1841560335a8"},"outputs":[{"data":{"text/plain":["['DESCR', 'data', 'filenames', 'target', 'target_names']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dir(data)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"elapsed":197,"status":"ok","timestamp":1632938424368,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"_hsArm2jK7wE","outputId":"95a63422-ec93-43d8-c9d4-912a4aeee268"},"outputs":[{"data":{"text/plain":["'.. _20newsgroups_dataset:\\n\\nThe 20 newsgroups text dataset\\n------------------------------\\n\\nThe 20 newsgroups dataset comprises around 18000 newsgroups posts on\\n20 topics split in two subsets: one for training (or development)\\nand the other one for testing (or for performance evaluation). The split\\nbetween the train and test set is based upon a messages posted before\\nand after a specific date.\\n\\nThis module contains two loaders. The first one,\\n:func:`sklearn.datasets.fetch_20newsgroups`,\\nreturns a list of the raw texts that can be fed to text feature\\nextractors such as :class:`~sklearn.feature_extraction.text.CountVectorizer`\\nwith custom parameters so as to extract feature vectors.\\nThe second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\\nreturns ready-to-use features, i.e., it is not necessary to use a feature\\nextractor.\\n\\n**Data Set Characteristics:**\\n\\n    =================   ==========\\n    Classes                     20\\n    Samples total            18846\\n    Dimensionality               1\\n    Features                  text\\n    =================   ==========\\n\\nUsage\\n~~~~~\\n\\nThe :func:`sklearn.datasets.fetch_20newsgroups` function is a data\\nfetching / caching functions that downloads the data archive from\\nthe original `20 newsgroups website`_, extracts the archive contents\\nin the ``~/scikit_learn_data/20news_home`` folder and calls the\\n:func:`sklearn.datasets.load_files` on either the training or\\ntesting set folder, or both of them::\\n\\n  >>> from sklearn.datasets import fetch_20newsgroups\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\')\\n\\n  >>> from pprint import pprint\\n  >>> pprint(list(newsgroups_train.target_names))\\n  [\\'alt.atheism\\',\\n   \\'comp.graphics\\',\\n   \\'comp.os.ms-windows.misc\\',\\n   \\'comp.sys.ibm.pc.hardware\\',\\n   \\'comp.sys.mac.hardware\\',\\n   \\'comp.windows.x\\',\\n   \\'misc.forsale\\',\\n   \\'rec.autos\\',\\n   \\'rec.motorcycles\\',\\n   \\'rec.sport.baseball\\',\\n   \\'rec.sport.hockey\\',\\n   \\'sci.crypt\\',\\n   \\'sci.electronics\\',\\n   \\'sci.med\\',\\n   \\'sci.space\\',\\n   \\'soc.religion.christian\\',\\n   \\'talk.politics.guns\\',\\n   \\'talk.politics.mideast\\',\\n   \\'talk.politics.misc\\',\\n   \\'talk.religion.misc\\']\\n\\nThe real data lies in the ``filenames`` and ``target`` attributes. The target\\nattribute is the integer index of the category::\\n\\n  >>> newsgroups_train.filenames.shape\\n  (11314,)\\n  >>> newsgroups_train.target.shape\\n  (11314,)\\n  >>> newsgroups_train.target[:10]\\n  array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\\n\\nIt is possible to load only a sub-selection of the categories by passing the\\nlist of the categories to load to the\\n:func:`sklearn.datasets.fetch_20newsgroups` function::\\n\\n  >>> cats = [\\'alt.atheism\\', \\'sci.space\\']\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\', categories=cats)\\n\\n  >>> list(newsgroups_train.target_names)\\n  [\\'alt.atheism\\', \\'sci.space\\']\\n  >>> newsgroups_train.filenames.shape\\n  (1073,)\\n  >>> newsgroups_train.target.shape\\n  (1073,)\\n  >>> newsgroups_train.target[:10]\\n  array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\\n\\nConverting text to vectors\\n~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\\nIn order to feed predictive or clustering models with the text data,\\none first need to turn the text into vectors of numerical values suitable\\nfor statistical analysis. This can be achieved with the utilities of the\\n``sklearn.feature_extraction.text`` as demonstrated in the following\\nexample that extract `TF-IDF`_ vectors of unigram tokens\\nfrom a subset of 20news::\\n\\n  >>> from sklearn.feature_extraction.text import TfidfVectorizer\\n  >>> categories = [\\'alt.atheism\\', \\'talk.religion.misc\\',\\n  ...               \\'comp.graphics\\', \\'sci.space\\']\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\',\\n  ...                                       categories=categories)\\n  >>> vectorizer = TfidfVectorizer()\\n  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\\n  >>> vectors.shape\\n  (2034, 34118)\\n\\nThe extracted TF-IDF vectors are very sparse, with an average of 159 non-zero\\ncomponents by sample in a more than 30000-dimensional space\\n(less than .5% non-zero features)::\\n\\n  >>> vectors.nnz / float(vectors.shape[0])\\n  159.01327...\\n\\n:func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which\\nreturns ready-to-use token counts features instead of file names.\\n\\n.. _`20 newsgroups website`: http://people.csail.mit.edu/jrennie/20Newsgroups/\\n.. _`TF-IDF`: https://en.wikipedia.org/wiki/Tf-idf\\n\\n\\nFiltering text for more realistic training\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\\nIt is easy for a classifier to overfit on particular things that appear in the\\n20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\\nhigh F-scores, but their results would not generalize to other documents that\\naren\\'t from this window of time.\\n\\nFor example, let\\'s look at the results of a multinomial Naive Bayes classifier,\\nwhich is fast to train and achieves a decent F-score::\\n\\n  >>> from sklearn.naive_bayes import MultinomialNB\\n  >>> from sklearn import metrics\\n  >>> newsgroups_test = fetch_20newsgroups(subset=\\'test\\',\\n  ...                                      categories=categories)\\n  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\\n  >>> clf = MultinomialNB(alpha=.01)\\n  >>> clf.fit(vectors, newsgroups_train.target)\\n  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\\n\\n  >>> pred = clf.predict(vectors_test)\\n  >>> metrics.f1_score(newsgroups_test.target, pred, average=\\'macro\\')\\n  0.88213...\\n\\n(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\\nthe training and test data, instead of segmenting by time, and in that case\\nmultinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\\nyet of what\\'s going on inside this classifier?)\\n\\nLet\\'s take a look at what the most informative features are:\\n\\n  >>> import numpy as np\\n  >>> def show_top10(classifier, vectorizer, categories):\\n  ...     feature_names = vectorizer.get_feature_names_out()\\n  ...     for i, category in enumerate(categories):\\n  ...         top10 = np.argsort(classifier.coef_[i])[-10:]\\n  ...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\\n  ...\\n  >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\\n  alt.atheism: edu it and in you that is of to the\\n  comp.graphics: edu in graphics it is for and of to the\\n  sci.space: edu it that is in and space to of the\\n  talk.religion.misc: not it you in is that and to of the\\n\\n\\nYou can now see many things that these features have overfit to:\\n\\n- Almost every group is distinguished by whether headers such as\\n  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\\n- Another significant feature involves whether the sender is affiliated with\\n  a university, as indicated either by their headers or their signature.\\n- The word \"article\" is a significant feature, based on how often people quote\\n  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\\n  wrote:\"\\n- Other features match the names and e-mail addresses of particular people who\\n  were posting at the time.\\n\\nWith such an abundance of clues that distinguish newsgroups, the classifiers\\nbarely have to identify topics from text at all, and they all perform at the\\nsame high level.\\n\\nFor this reason, the functions that load 20 Newsgroups data provide a\\nparameter called **remove**, telling it what kinds of information to strip out\\nof each file. **remove** should be a tuple containing any subset of\\n``(\\'headers\\', \\'footers\\', \\'quotes\\')``, telling it to remove headers, signature\\nblocks, and quotation blocks respectively.\\n\\n  >>> newsgroups_test = fetch_20newsgroups(subset=\\'test\\',\\n  ...                                      remove=(\\'headers\\', \\'footers\\', \\'quotes\\'),\\n  ...                                      categories=categories)\\n  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\\n  >>> pred = clf.predict(vectors_test)\\n  >>> metrics.f1_score(pred, newsgroups_test.target, average=\\'macro\\')\\n  0.77310...\\n\\nThis classifier lost over a lot of its F-score, just because we removed\\nmetadata that has little to do with topic classification.\\nIt loses even more if we also strip this metadata from the training data:\\n\\n  >>> newsgroups_train = fetch_20newsgroups(subset=\\'train\\',\\n  ...                                       remove=(\\'headers\\', \\'footers\\', \\'quotes\\'),\\n  ...                                       categories=categories)\\n  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\\n  >>> clf = MultinomialNB(alpha=.01)\\n  >>> clf.fit(vectors, newsgroups_train.target)\\n  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\\n\\n  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\\n  >>> pred = clf.predict(vectors_test)\\n  >>> metrics.f1_score(newsgroups_test.target, pred, average=\\'macro\\')\\n  0.76995...\\n\\nSome other classifiers cope better with this harder version of the task. Try\\nrunning :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without\\nthe ``--filter`` option to compare the results.\\n\\n.. topic:: Data Considerations\\n\\n  The Cleveland Indians is a major league baseball team based in Cleveland,\\n  Ohio, USA. In December 2020, it was reported that \"After several months of\\n  discussion sparked by the death of George Floyd and a national reckoning over\\n  race and colonialism, the Cleveland Indians have decided to change their\\n  name.\" Team owner Paul Dolan \"did make it clear that the team will not make\\n  its informal nickname -- the Tribe -- its new team name.\" \"It’s not going to\\n  be a half-step away from the Indians,\" Dolan said.\"We will not have a Native\\n  American-themed name.\"\\n\\n  https://www.mlb.com/news/cleveland-indians-team-name-change\\n\\n.. topic:: Recommendation\\n\\n  - When evaluating text classifiers on the 20 Newsgroups data, you\\n    should strip newsgroup-related metadata. In scikit-learn, you can do this\\n    by setting ``remove=(\\'headers\\', \\'footers\\', \\'quotes\\')``. The F-score will be\\n    lower because it is more realistic.\\n  - This text dataset contains data which may be inappropriate for certain NLP\\n    applications. An example is listed in the \"Data Considerations\" section\\n    above. The challenge with using current text datasets in NLP for tasks such\\n    as sentence completion, clustering, and other applications is that text\\n    that is culturally biased and inflammatory will propagate biases. This\\n    should be taken into consideration when using the dataset, reviewing the\\n    output, and the bias should be documented.\\n\\n.. topic:: Examples\\n\\n   * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`\\n\\n   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\\n'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data.DESCR"]},{"cell_type":"markdown","metadata":{"id":"hfTROeEzt1oA"},"source":["How  would you classify the first post? i.e., Religion or Atheism?"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":192,"status":"ok","timestamp":1632938427504,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"yT87GZN3LMTk","outputId":"ed937d60-9c6c-4bf4-8311-39b73ed6b714"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'list'>\n","1427\n","From: agr00@ccc.amdahl.com (Anthony G Rose)\n","Subject: Re: Who's next?  Mormons and Jews?\n","Reply-To: agr00@JUTS.ccc.amdahl.com (Anthony G Rose)\n","Organization: Amdahl Corporation, Sunnyvale CA\n","Lines: 18\n","\n","In article <1993Apr20.142356.456@ra.royalroads.ca> mlee@post.RoyalRoads.ca (Malcolm Lee) writes:\n",">\n",">In article <C5rLps.Fr5@world.std.com>, jhallen@world.std.com (Joseph H Allen) writes:\n",">|> In article <1qvk8sINN9vo@clem.handheld.com> jmd@cube.handheld.com (Jim De Arras) writes:\n",">|> \n",">|> It was interesting to watch the 700 club today.  Pat Robertson said that the\n",">|> \"Branch Dividians had met the firey end for worshipping their false god.\" He\n",">|> also said that this was a terrible tragedy and that the FBI really blew it.\n",">\n",">I don't necessarily agree with Pat Robertson.  Every one will be placed before\n",">the judgement seat eventually and judged on what we have done or failed to do\n",">on this earth.  God allows people to choose who and what they want to worship.\n","\n","I'm sorry, but He does not!  Ever read the FIRST commandment?\n","\n",">Worship of money is one of the greatest religions in this country.\n","\n","You mean, false religion!\n","\n"]}],"source":["print(type(data.data))\n","print(len(data.data))\n","print(data.data[0])"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281,"status":"ok","timestamp":1632938484589,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"PFidKM9rL8Fl","outputId":"5e64610c-fcfa-429d-f596-f2171e46c24b"},"outputs":[{"name":"stdout","output_type":"stream","text":["['alt.atheism', 'talk.religion.misc']\n"]}],"source":["print(data['target_names'])"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":154,"status":"ok","timestamp":1632938486021,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"A9dazy2JMDfC","outputId":"e6330686-4378-426e-d17d-9f9222809372"},"outputs":[{"name":"stdout","output_type":"stream","text":["1427\n"]}],"source":["print(len(data['target']))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157,"status":"ok","timestamp":1632938487696,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"b5vB8VNwM8U7","outputId":"3ec5afd3-038f-4fbb-a83a-2db3a030467f"},"outputs":[{"data":{"text/plain":["array([1, 1, 0, 1, 0, 1, 1, 0, 0, 1], dtype=int64)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["data.target[:10]"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":177,"status":"ok","timestamp":1632938489162,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"Kt1K208JLa2i","outputId":"e7ce6138-c856-434e-ec45-2023c180f7d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["1427\n"]},{"data":{"text/plain":["'C:\\\\Users\\\\somer\\\\scikit_learn_data\\\\20news_home\\\\20news-bydate-train\\\\talk.religion.misc\\\\84101'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["print(len(data.filenames))\n","data.filenames[0]"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":166,"status":"ok","timestamp":1632938491075,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"jsUivZZdNAEU","outputId":"44e2dbe5-45d1-41c7-f5c1-3adeaf5df2e7"},"outputs":[{"data":{"text/plain":["array([0, 1], dtype=int64)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["np.unique(data.target)"]},{"cell_type":"markdown","metadata":{"id":"lMS6iu0s4a8C"},"source":["###1.2.3 Function to clean the data"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":165,"status":"ok","timestamp":1632938493796,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"mTTyxOuB-Xzr"},"outputs":[],"source":["def clean_data(text):\n","    \"\"\"\n","    Accepts a single text document and performs several regex substitutions in order to clean the document. \n","    \n","    Parameters\n","    ----------\n","    text: string or object \n","    \n","    Returns\n","    -------\n","    text: string or object\n","    \"\"\"\n","    \n","    # order of operations - apply the expression from top to bottom\n","    email_regex = r\"From: \\S*@\\S*\\s?\"\n","    non_alpha = '[^a-zA-Z]'\n","    multi_white_spaces = \"[ ]{2,}\"\n","    \n","    text = re.sub(email_regex, \"\", text)\n","    text = re.sub(non_alpha, ' ', text)\n","    text = re.sub(multi_white_spaces, \" \", text)\n","    \n","    # apply case normalization \n","    return text.lower().lstrip().rstrip()"]},{"cell_type":"markdown","metadata":{"id":"qLU7NToMHGUU"},"source":["### 1.2.4 Create and run a pipeline"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":374,"status":"ok","timestamp":1632938497029,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"LtzyrhM--Xzr","scrolled":true},"outputs":[],"source":["# prep data, instantiate a model, create pipeline object, and run a gridsearch \n","\n","###BEGIN SOLUTION\n","# save our model input data to X\n","X = data.data\n","\n","# save our targets/labels to Y \n","y = data.target\n","\n","# clean our docs \n","X_clean = [clean_data(post) for post in data.data]\n","\n","# Create Pipeline Components\n","\n","# create vectorizer\n","tfidf = TfidfVectorizer(stop_words=\"english\", tokenizer=None) # data transformer \n","\n","# create classifier\n","rfc = RandomForestClassifier(random_state=42) # estimator \n","\n","# Instantiate a pipeline object -- which is a list of tuples\n","#   Each tuple specifies (name of the pipeline component, the pipeline component)\n","pipe = Pipeline([(\"vect\", tfidf), # data transformer\n","                 (\"clf\", rfc)])   # classifier \n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21585,"status":"ok","timestamp":1632938521470,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"YGw2hhmfI6lP","outputId":"5eb93951-6882-4b02-88fb-fe12257dec7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 32 candidates, totalling 96 fits\n","CPU times: total: 2.36 s\n","Wall time: 21.4 s\n"]},{"data":{"text/plain":["GridSearchCV(cv=3,\n","             estimator=Pipeline(steps=[('vect',\n","                                        TfidfVectorizer(stop_words='english')),\n","                                       ('clf',\n","                                        RandomForestClassifier(random_state=42))]),\n","             n_jobs=-2,\n","             param_grid={'clf__max_depth': (15, 20),\n","                         'clf__n_estimators': (10, 100),\n","                         'vect__max_df': (0.75, 1.0),\n","                         'vect__max_features': (500, 1000),\n","                         'vect__min_df': (2, 10)},\n","             verbose=1)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","# create a hyper-parameter dictionary for BOTH our vectorizer and our ML model \n","# here we will determine which tfidf parameter values lead to the best performing model\n","parameters = {\n","    'vect__max_df': ( 0.75, 1.0),  # When its in 75% of docs then we ignore?\n","    'vect__min_df': ( 2, 10),  # Said, 2 ngrams was too much?\n","#     'vect__stop_words': (\"english\", None), \n","#     'vect__lowercase': (True, False)\n","    'vect__max_features': (500, 1000),  # either 500 or 1000, find which is better.\n","    'clf__n_estimators':(10, 100),  # 10 or 100 trees only choices?\n","    'clf__max_depth':(15, 20)  # \n","}\n","# 2^5 = 32 combinations\n","# Instantiate a GridSearchCV object\n","gs = GridSearchCV(pipe, param_grid=parameters, n_jobs=-2, cv=3, verbose=1) # Because cv=3 we're doing the 32 three times.\n","# Note: For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. For example with n_jobs=-2, all CPUs but one are used.\n","\n","gs.fit(X_clean, y)\n","###END SOLUTION\n","# >> Fitting 3 folds for each of 32 candidates, totalling 96 fits"]},{"cell_type":"markdown","metadata":{"id":"2fkn8N8RQyLS"},"source":["Establishing a baseline accuracy with a naive model"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":160,"status":"ok","timestamp":1632938548251,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"A8CtJ3tYNUWX","outputId":"51a188ca-fa1f-49e9-defc-141f3bf7069b"},"outputs":[{"data":{"text/plain":["0.4400840925017519"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["frac_ones = y.sum()/len(y)\n","frac_ones"]},{"cell_type":"markdown","metadata":{"id":"H1RoV5VmQ_IY"},"source":["Since the majority class is zeros, naive model is to predict all zeros!"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":174,"status":"ok","timestamp":1632938551396,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"_onhKqPpRDPV"},"outputs":[],"source":["y_naive_pred = np.zeros((1,len(y)))"]},{"cell_type":"markdown","metadata":{"id":"k2ot57oTRVgO"},"source":["Naive model error"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":173,"status":"ok","timestamp":1632938552964,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"9gdzoMVgR1Ab","outputId":"cf4c10a8-93ac-441a-b7fc-2d2233019801"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.4400840925017519\n"]}],"source":["frac_error = np.abs(y_naive_pred - y).sum()/len(y)\n","print(frac_error)"]},{"cell_type":"markdown","metadata":{"id":"A1aI4d2xRYL6"},"source":["Naive model accuracy"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157,"status":"ok","timestamp":1632938555369,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"oCsGDTerSTlo","outputId":"16041410-b45a-4d96-ad17-87248cdf5a20"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.559915907498248\n"]}],"source":["baseline_accuracy = 1-frac_error\n","print(baseline_accuracy)"]},{"cell_type":"markdown","metadata":{"id":"7PruqYynQqHA"},"source":["Pipeline results after hyperparameter tuning!"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":158,"status":"ok","timestamp":1632938557727,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"LepOoI_qNZm-","outputId":"c299d4a1-208e-453a-8159-6c7bfc63434f"},"outputs":[{"data":{"text/plain":["0.8836812619784755"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["gs.best_score_\n","# >> 0.8836812619784755\n","# You can try stop words and other params to improve."]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":228,"status":"ok","timestamp":1632938560441,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"ykKsZC27NdoF","outputId":"c15fe85f-48ef-47ee-f49d-7611941a9010"},"outputs":[{"data":{"text/plain":["{'clf__max_depth': 20,\n"," 'clf__n_estimators': 100,\n"," 'vect__max_df': 1.0,\n"," 'vect__max_features': 1000,\n"," 'vect__min_df': 10}"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["gs.best_params_"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237,"status":"ok","timestamp":1632938562725,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"puhDF0KrN-Vv","outputId":"3b6f9831-583d-43a1-a7f9-07e1278d74df"},"outputs":[{"data":{"text/plain":["Pipeline(steps=[('vect',\n","                 TfidfVectorizer(max_features=1000, min_df=10,\n","                                 stop_words='english')),\n","                ('clf', RandomForestClassifier(max_depth=20, random_state=42))])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["best_model = gs.best_estimator_\n","best_model"]},{"cell_type":"markdown","metadata":{"id":"_67VDlqCQisM"},"source":["Getting your predictions using the pipeline"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":352,"status":"ok","timestamp":1632938566302,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"1zpAdn_6NqTs"},"outputs":[],"source":["# because the vectorizer was included in the pipeline object\n","# we can simply pass in raw text data into gs and it will provide a classification\n","y_pred = gs.predict(X_clean)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1632938568392,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"7pDl_ssMN234","outputId":"d84291ce-fa07-460f-faff-ace440cba92f"},"outputs":[{"data":{"text/plain":["array([1, 1, 0, ..., 1, 1, 0], dtype=int64)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# this is what you would submit to Kaggle\n","y_pred"]},{"cell_type":"markdown","metadata":{"id":"r0fnovIV-Xzu"},"source":["#2. Latent Semantic Analysis (Learn)\n","a.k.a. Latent Semantic Indexing\n","<a id=\"p2\"></a>"]},{"cell_type":"markdown","metadata":{"id":"4LMo4MRC-Xzv"},"source":["## Overview"]},{"cell_type":"markdown","metadata":{"id":"GQmJymbk-Xzv"},"source":["![](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1538411402/image3_maagmh.png)"]},{"cell_type":"markdown","metadata":{"id":"TFQQ9Zs_OhE_"},"source":["**Take Aways:** LSA has two main benefits\n","\n","1. Dimensionality Reduction \n","2. Topic Modeling (feature engineering) - identifies latent (hidden) topics that are present in our doc-term matrix. <br>\n","This is something that counting vectorizers can't do (i.e. CountVectorizer, TFIDF)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"executionInfo":{"elapsed":171,"status":"ok","timestamp":1632938573275,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"O2OQjld_-Xzv","outputId":"0999758f-f81c-4144-e633-85cf17f82d60"},"outputs":[{"data":{"image/jpeg":"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","text/html":["\n","        <iframe\n","            width=\"1024\"\n","            height=\"576\"\n","            src=\"https://www.youtube.com/embed/OvzJiur55vo\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.YouTubeVideo at 0x14f4e0e54e0>"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import YouTubeVideo\n","YouTubeVideo('OvzJiur55vo', width=1024, height=576)"]},{"cell_type":"markdown","metadata":{"id":"4oFb4L6_-Xzw"},"source":["## 2.1 An example of Latent Semantic Analysis\n","\n","Before we apply Latent Semantic Analysis in a pipeline, let's work through a simple example together in order to better understand how LSA works and develop an intuition along the way. \n","\n","First, if you haven't already, watch the short video provided above. We will be implementing the example from the video in our notebook. "]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":162,"status":"ok","timestamp":1632938576955,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"URNyczca-Xzw"},"outputs":[],"source":["# Import\n","\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","svd = TruncatedSVD(n_components=2, # number of topics to generate (also the size of the new feature space)\n","                   algorithm='randomized',\n","                   n_iter=10)\n","\n","# let's use the same data that was used in the video for consistancy \n","\n","        # topic 1 data \n","data = [\"pizza\", \n","        \"pizza hamburger cookie\",\n","        \"hamburger\", \n","        # topic 2 data\n","        \"ramen\", \n","        \"sushi\", \n","        \"ramen sushi\"]"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1632938579246,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"6gA7-iDx-Xzx","nbgrader":{"grade":false,"grade_id":"cell-74a4478e1d50513b","locked":false,"schema_version":3,"solution":true,"task":false},"outputId":"784bb0be-a9e7-4284-f89c-64ad67087d3e"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\somer\\miniconda3\\envs\\DeepLearning\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cookie</th>\n","      <th>hamburger</th>\n","      <th>pizza</th>\n","      <th>ramen</th>\n","      <th>sushi</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>pizza</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>pizza hamburger cookie</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hamburger</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>ramen</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>sushi</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>ramen sushi</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        cookie  hamburger  pizza  ramen  sushi\n","pizza                        0          0      1      0      0\n","pizza hamburger cookie       1          1      1      0      0\n","hamburger                    0          1      0      0      0\n","ramen                        0          0      0      1      0\n","sushi                        0          0      0      0      1\n","ramen sushi                  0          0      0      1      1"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# CREATE Term-Frequency matrix \n","\n","###BEGIN SOLUTION\n","# use CountVectorizer to create a Term-Frequency matrix (a.k.a. Doc-Term Matrix )\n","tf_vectorizer = CountVectorizer()\n","tfm = tf_vectorizer.fit_transform(data)\n","tfm = pd.DataFrame(data=tfm.toarray(), columns=tf_vectorizer.get_feature_names())\n","\n","# switch integer indicies with terms\n","tfm.index = data\n","tfm\n","###END SOLUTION"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":185,"status":"ok","timestamp":1632938581958,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"u29NFf0z-Xzx","nbgrader":{"grade":false,"grade_id":"cell-cfc0e060c5491e20","locked":false,"schema_version":3,"solution":true,"task":false},"outputId":"3b19dc90-dcdd-4dd3-be00-840f77cc2154"},"outputs":[{"data":{"text/plain":["array([[ 0.63,  0.  ],\n","       [ 1.72,  0.  ],\n","       [ 0.63,  0.  ],\n","       [-0.  ,  0.71],\n","       [-0.  ,  0.71],\n","       [-0.  ,  1.41]])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Use SVD to transform our Term-Frequency matrix into a Topic matrix with reduced dimensionality\n","\n","\n","###BEGIN SOLUTION\n","# Use SVD to transform our Term-Frequency matrix into a Topic matrix with reduced dimensionality\n","X_reduced = svd.fit_transform(tfm)\n","\n","# this is the output of SVD\n","# same number of rows \n","# number of features has been reduced to 2 \n","X_reduced.round(2)\n","###END SOLUTION"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":182,"status":"ok","timestamp":1632938584641,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"6o9vAW28-Xzy","nbgrader":{"grade":false,"grade_id":"cell-f93d7b170dec7dfd","locked":false,"schema_version":3,"solution":true,"task":false},"outputId":"bb8b51d6-3fd0-4b5d-db39-8b1a31f5d901"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topic_1</th>\n","      <th>topic_2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>pizza</th>\n","      <td>0.63</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>pizza hamburger cookie</th>\n","      <td>1.72</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>hamburger</th>\n","      <td>0.63</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>ramen</th>\n","      <td>-0.00</td>\n","      <td>0.71</td>\n","    </tr>\n","    <tr>\n","      <th>sushi</th>\n","      <td>-0.00</td>\n","      <td>0.71</td>\n","    </tr>\n","    <tr>\n","      <th>ramen sushi</th>\n","      <td>-0.00</td>\n","      <td>1.41</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        topic_1  topic_2\n","pizza                      0.63     0.00\n","pizza hamburger cookie     1.72     0.00\n","hamburger                  0.63     0.00\n","ramen                     -0.00     0.71\n","sushi                     -0.00     0.71\n","ramen sushi               -0.00     1.41"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# let's move X_reduced into a dataframe and rename the indices and columns for interpretability  \n","\n","###BEGIN SOLUION\n","# let's move X_reduced into a dataframe and rename the indicies and columns for interpretability  \n","topic_cols = [\"topic_1\", \"topic_2\"]\n","dtm_reduced = pd.DataFrame(data=X_reduced.round(2), columns=topic_cols)\n","dtm_reduced.index = data\n","dtm_reduced\n","###END SOLUTION"]},{"cell_type":"markdown","metadata":{"id":"ZhcqeW6y8GGW"},"source":["## 2.2 Build a Latent Semantic Analysis (LSA) pipeline\n","Now that we've gone through an example of applying LSA on a small dataset, let's implement it in a classification pipeline to run on the `20newsgroups`data.  \n"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":157,"status":"ok","timestamp":1632938588193,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"61evvltl-Xzy","nbgrader":{"grade":false,"grade_id":"cell-0ff7ed88cbc5eb32","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# build a pipeline, incorporate SVD, and run a gridsearch \n","\n","###BEGIN SOLUTION -- ask svd to truncate to the best 100 principal components, i.e. find 100 \"topics\"\n","svd = TruncatedSVD(n_components=100, \n","                   algorithm='randomized',\n","                   n_iter=10)\n","\n","# instantiate a pipeline object\n","lsi = Pipeline([(\"vect\", tfidf), # creating our term-doc matrix\n","                (\"svd\", svd)]) # apply svd to our term-doc matrix \n","\n","# instantiate a pipeline object\n","pipe = Pipeline([(\"lsi\", lsi), # data transform\n","                 (\"clf\", rfc)]) # estimator \n","\n","# a nice default starter set for hyper-parameter values\n","# include more parameters and values to try to increase model performance \n","params = { \n","    'lsi__svd__n_components': [10, 100, 200],\n","    'lsi__vect__max_df':[.95,  1.0],\n","    'clf__n_estimators':[100, 300, 1000], \n","    'clf__max_depth':(15, 20)\n","}\n","\n","\n","gs = GridSearchCV(pipe,\n","                  param_grid=params, \n","                  cv=3, \n","                  n_jobs=-2, \n","                  verbose=1 )\n","\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103304,"status":"ok","timestamp":1632938809272,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"xAQlfwOXRree","outputId":"fdb2115d-8425-44ea-b758-d7e318d95b2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 36 candidates, totalling 108 fits\n","CPU times: total: 16.2 s\n","Wall time: 2min 36s\n"]},{"data":{"text/plain":["GridSearchCV(cv=3,\n","             estimator=Pipeline(steps=[('lsi',\n","                                        Pipeline(steps=[('vect',\n","                                                         TfidfVectorizer(stop_words='english')),\n","                                                        ('svd',\n","                                                         TruncatedSVD(n_components=100,\n","                                                                      n_iter=10))])),\n","                                       ('clf',\n","                                        RandomForestClassifier(random_state=42))]),\n","             n_jobs=-2,\n","             param_grid={'clf__max_depth': (15, 20),\n","                         'clf__n_estimators': [100, 300, 1000],\n","                         'lsi__svd__n_components': [10, 100, 200],\n","                         'lsi__vect__max_df': [0.95, 1.0]},\n","             verbose=1)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","gs.fit(X_clean, y)\n","###END SOLUTION"]},{"cell_type":"markdown","metadata":{"id":"FjRKarGlu7zm"},"source":["What results can we get from the `gs` object?"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227,"status":"ok","timestamp":1632938814986,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"IWzKatW2ckuo","outputId":"1ae3fb14-e39e-48fe-c8ed-92e455308e81"},"outputs":[{"data":{"text/plain":["['__abstractmethods__',\n"," '__class__',\n"," '__delattr__',\n"," '__dict__',\n"," '__dir__',\n"," '__doc__',\n"," '__eq__',\n"," '__format__',\n"," '__ge__',\n"," '__getattribute__',\n"," '__getstate__',\n"," '__gt__',\n"," '__hash__',\n"," '__init__',\n"," '__init_subclass__',\n"," '__le__',\n"," '__lt__',\n"," '__module__',\n"," '__ne__',\n"," '__new__',\n"," '__reduce__',\n"," '__reduce_ex__',\n"," '__repr__',\n"," '__setattr__',\n"," '__setstate__',\n"," '__sizeof__',\n"," '__str__',\n"," '__subclasshook__',\n"," '__weakref__',\n"," '_abc_impl',\n"," '_check_feature_names',\n"," '_check_n_features',\n"," '_check_refit_for_multimetric',\n"," '_estimator_type',\n"," '_format_results',\n"," '_get_param_names',\n"," '_get_tags',\n"," '_more_tags',\n"," '_pairwise',\n"," '_repr_html_',\n"," '_repr_html_inner',\n"," '_repr_mimebundle_',\n"," '_required_parameters',\n"," '_run_search',\n"," '_select_best_index',\n"," '_validate_data',\n"," 'best_estimator_',\n"," 'best_index_',\n"," 'best_params_',\n"," 'best_score_',\n"," 'classes_',\n"," 'cv',\n"," 'cv_results_',\n"," 'decision_function',\n"," 'error_score',\n"," 'estimator',\n"," 'fit',\n"," 'get_params',\n"," 'inverse_transform',\n"," 'multimetric_',\n"," 'n_features_in_',\n"," 'n_jobs',\n"," 'n_splits_',\n"," 'param_grid',\n"," 'pre_dispatch',\n"," 'predict',\n"," 'predict_log_proba',\n"," 'predict_proba',\n"," 'refit',\n"," 'refit_time_',\n"," 'return_train_score',\n"," 'score',\n"," 'score_samples',\n"," 'scorer_',\n"," 'scoring',\n"," 'set_params',\n"," 'transform',\n"," 'verbose']"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["dir(gs)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":217,"status":"ok","timestamp":1632938827783,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"H3aOnBOMPlBp","outputId":"b750a026-edf8-4ce3-90cd-5d360f10c132"},"outputs":[{"data":{"text/plain":["{'clf__max_depth': 20,\n"," 'clf__n_estimators': 300,\n"," 'lsi__svd__n_components': 100,\n"," 'lsi__vect__max_df': 0.95}"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["gs.best_params_"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1632938809789,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"5DntWTP9PpTo","outputId":"ce8c8ddc-c232-439c-e833-5b439595b502"},"outputs":[{"data":{"text/plain":["0.8752602093468966"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["gs.best_score_\n","# 0.8738567005749669"]},{"cell_type":"markdown","metadata":{"id":"up_BlkQg-Xzz"},"source":["## Challenge\n","\n","Continue to apply Latent Semantic Indexing (LSI) to various datasets. "]},{"cell_type":"markdown","metadata":{"id":"_msTRGxU-Xzz"},"source":["#3. Word Embeddings with Spacy (Learn)\n","In this section we'll complete our preparation for Lambda School's [Whisky Classification Kaggle Competition](https://www.kaggle.com/c/whiskey-201911/)\n","<a id=\"p3\"></a>"]},{"cell_type":"markdown","metadata":{"id":"P5XoeJoP-Xzz","toc-hr-collapsed":true},"source":["## Follow Along\n","1. Join the [Whisky Classification Kaggle Competition](https://www.kaggle.com/c/whiskey-201911/)\n","2. Download the data to your local machine, then upload the files to your Colab notebook by first clicking the **folder icon** in the left sidebar, then clicking the **folder with the up arrow icon** that appears under \"Files\" in the left sidebar. The files should now be in the /content folder. To get the path to an object that appears in the left sidebar, hover over it, click the three vertical dots that appear on the right, then select \"Copy path\"."]},{"cell_type":"markdown","metadata":{"id":"QvrgCtF4-Xzz"},"source":["## 3.1 Get the data\n","Download the `.csv` files from the [Whisky Classification Kaggle Competition](https://www.kaggle.com/c/whiskey-201911/) to your local machine, <br>\n","then upload them to this Colab notebook."]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":163,"status":"ok","timestamp":1632938878694,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"Fw2_45qxvPCH"},"outputs":[],"source":["test = pd.read_csv('test.csv')\n","train = pd.read_csv('train.csv')  # path ../folder/file"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":199,"status":"ok","timestamp":1632938881656,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"NTsnRcuGph1o","outputId":"1629a71d-59df-4358-b825-d91a5ffc3e70"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>ratingCategory</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1321</td>\n","      <td>\\r\\nSometimes, when whisky is batched, a few l...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3861</td>\n","      <td>\\r\\nAn uncommon exclusive bottling of a 6 year...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>655</td>\n","      <td>\\r\\nThis release is a port version of Amrut’s ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>555</td>\n","      <td>\\r\\nThis 41 year old single cask was aged in a...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1965</td>\n","      <td>\\r\\nQuite herbal on the nose, with aromas of d...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4082</th>\n","      <td>3342</td>\n","      <td>\\r\\nWhat lies beneath the surface of Dewar’s? ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4083</th>\n","      <td>3130</td>\n","      <td>\\r\\nAfter 6 to 7 years of maturation in bourbo...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4084</th>\n","      <td>2811</td>\n","      <td>\\r\\nBright, delicate, and approachable. While ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4085</th>\n","      <td>478</td>\n","      <td>\\r\\nI’m calling this the pitmaster’s dram: the...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4086</th>\n","      <td>1209</td>\n","      <td>\\r\\nSpicy sultanas, greengage plums, toffee, a...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4087 rows × 3 columns</p>\n","</div>"],"text/plain":["        id                                        description  ratingCategory\n","0     1321  \\r\\nSometimes, when whisky is batched, a few l...               1\n","1     3861  \\r\\nAn uncommon exclusive bottling of a 6 year...               0\n","2      655  \\r\\nThis release is a port version of Amrut’s ...               1\n","3      555  \\r\\nThis 41 year old single cask was aged in a...               1\n","4     1965  \\r\\nQuite herbal on the nose, with aromas of d...               1\n","...    ...                                                ...             ...\n","4082  3342  \\r\\nWhat lies beneath the surface of Dewar’s? ...               1\n","4083  3130  \\r\\nAfter 6 to 7 years of maturation in bourbo...               1\n","4084  2811  \\r\\nBright, delicate, and approachable. While ...               1\n","4085   478  \\r\\nI’m calling this the pitmaster’s dram: the...               1\n","4086  1209  \\r\\nSpicy sultanas, greengage plums, toffee, a...               1\n","\n","[4087 rows x 3 columns]"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["train"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151,"status":"ok","timestamp":1632938885501,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"6vQaYqOnpnyi","outputId":"a2283dfd-a61a-4100-ef68-6a5c88b9ed1e"},"outputs":[{"data":{"text/plain":["1    2881\n","0    1141\n","2      65\n","Name: ratingCategory, dtype: int64"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["train['ratingCategory'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"3nNUOqjrmSjB"},"source":["##3.2 Build a classification model that is trained on the word vectors from `spacy`<br>\n","Question: does `spacy` use `CountVectorizer()`, `TfidfVectorizer()` or `word2vec` to numericalize text?<br>\n","Run the classification model on the Whisky data set and get a preliminary result<br>\n"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45677,"status":"ok","timestamp":1632941049292,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"9w3ihOt0-Xz0","nbgrader":{"grade":false,"grade_id":"cell-30f6f3d27deb63a3","locked":false,"schema_version":3,"solution":true,"task":false},"outputId":"e123d09e-bec6-465e-94f3-4a495dc73daa"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 1min 15s\n","Wall time: 1min 21s\n"]},{"data":{"text/plain":["RandomForestClassifier(oob_score=True)"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","# build a model that is trained on word vectors \n","\n","###BEGIN SOLUTION\n","def get_word_vectors(docs):\n","    \"\"\"\n","    This serves as both our tokenizer and vectorizer. \n","    Returns a list of document vectors, i.e. our doc-term matrix\n","    \"\"\"\n","    return [nlp(doc).vector for doc in docs]\n","    # Here there is a lot to understand so should look back at class recordings\n","\n","# raw text data for train and test sets\n","X_train_text = train[\"description\"]\n","X_test_text = test[\"description\"]\n","\n","# transform raw data into doc-term matrices for train and test sets \n","X_train = get_word_vectors(X_train_text)\n","X_test = get_word_vectors(X_test_text)\n","\n","# save ratings to y vector\n","y_train = train[\"ratingCategory\"]\n","\n","# create RF model, use out-of-bag (oob) score for a quick estimate of generalization performance\n","# For best results, however, you want to do hyperparameter tuning using GridSearchCV \n","rfc = RandomForestClassifier(oob_score=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rfc.fit(X_train, y_train)\n","###END SOLUTION"]},{"cell_type":"markdown","metadata":{"id":"5rGDYDUC8Z4T"},"source":["Questions: \n","What information do the entries of of `X_train` contain? \n","Why does each element in `X_train` have the following shape?"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1632942259756,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"9fLRqQcC8A0A","outputId":"370907aa-07e6-4442-ca84-26e33795c947"},"outputs":[{"data":{"text/plain":["(300,)"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["X_train[0].shape"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1632941106527,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"8Wg4PZaKdLZ5","outputId":"a5befa3d-fd66-491c-ef95-67e4517444cb"},"outputs":[{"data":{"text/plain":["0.9997553217518963"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["# train set accuracy -- massively overfitted!\n","rfc.score(X_train, y_train)"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":164,"status":"ok","timestamp":1632941112075,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"_EdJRdPpdN-t","outputId":"fbc84f0a-fa08-4301-f0df-051b7ff7e687"},"outputs":[{"data":{"text/plain":["0.7274284316124296"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["# out-of-bag accuracy score, which can be thought of as a proxy for the test set score \n","rfc.oob_score_"]},{"cell_type":"markdown","metadata":{"id":"WHpWG3LC-Xz1"},"source":["## Challenge  -- this afternoon's lab module assignment\n","\n","1. Join Lambda School's [Whisky Classification Kaggle Competition](https://www.kaggle.com/c/whiskey-201911/)\n","2. Download the data\n","3. Train a model & try: \n","    - Creating a Text Extraction & Classification Pipeline\n","    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n","    - Add some Latent Semantic Indexing (LSI) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n","    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n","4. Make a submission to Kaggle \n","\n","Note: You can put together your project from code snippets from the current Colab notebook. <br>\n","Alternatively, you can adapt and refactor this [Colab notebook](https://drive.google.com/file/d/1ZY-P33tXD5y-VucOjg2TXO5OAQBWuTLf/view?usp=sharing) to work with the Kaggle data for your project."]},{"cell_type":"markdown","metadata":{"id":"Gylf8coS-Xz1"},"source":["# Review\n","\n","To review this module: \n","* Continue working on the Kaggle competition\n","* Find another text classification task to work on"]}],"metadata":{"accelerator":"GPU","celltoolbar":"Create Assignment","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"LS_DS_413_Document_Classification_Lecture.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}
