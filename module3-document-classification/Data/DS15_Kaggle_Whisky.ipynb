{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.0.4-cp310-none-win_amd64.whl (73.5 MB)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.19.1-py3-none-any.whl (46 kB)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.6.0-py2.py3-none-any.whl (27.7 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from catboost) (1.8.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from catboost) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from catboost) (1.21.5)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly, graphviz, catboost\n",
      "Successfully installed catboost-1.0.4 graphviz-0.19.1 plotly-5.6.0 tenacity-8.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting lightgbmNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading lightgbm-3.3.2-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from lightgbm) (1.8.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n",
      "Requirement already satisfied: xgboost in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\somer\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from xgboost) (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\somer\\miniconda3\\envs\\DeepLearning\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "## I. IMPORTS & INSTALLS\n",
    "##\ta. GradientBoostingClassifier\n",
    "#!python -m spacy download en_core_web_md\n",
    "%pip install catboost\n",
    "%pip install lightgbm\n",
    "%pip install xgboost\n",
    "\n",
    "## \tb. MODULES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm\timport LGBMClassifier\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV #, HalvingRandomSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "#import num2words\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##\tc. DATA\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>sometimes when whisky is batched a few leftove...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>an uncommon exclusive bottling of a year old c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>this release is a port version of amrut s inte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>this year old single cask was aged in a sherry...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>quite herbal on the nose with aromas of dried ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  sometimes when whisky is batched a few leftove...               1\n",
       "1  3861  an uncommon exclusive bottling of a year old c...               0\n",
       "2   655  this release is a port version of amrut s inte...               1\n",
       "3   555  this year old single cask was aged in a sherry...               1\n",
       "4  1965  quite herbal on the nose with aromas of dried ...               1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## II. EDA\n",
    "train.head()\n",
    "# train.shape # >> (4087, 3)\n",
    "# test.shape # >> (1022, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## III. DEFINE TERMS\n",
    "target = 'ratingCategory'\n",
    "features = 'description'\n",
    "X = train[features]\n",
    "y = train[target]\n",
    "assert len(X) == len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sometimes, when whisky is batched, a few leftover barrels are returned to the warehouse. Canadian Club recently pulled and vatted several of these from the 1970s. Acetone, Granny Smith apples, and fresh-cut white cedar showcase this long age. Complex and spicy, yet reserved, this dram is ripe with strawberries, canned pears, cloves, pepper, and faint flowers, then slightly pulling oak tannins. Distinct, elegant, and remarkably vibrant, this ancient Canadian Club is anything but tired. (Australia only) A$133\n",
      "sometimes when whisky is batched a few leftover barrels are returned to the warehouse canadian club recently pulled and vatted several of these from the s acetone granny smith apples and fresh cut white cedar showcase this long age complex and spicy yet reserved this dram is ripe with strawberries canned pears cloves pepper and faint flowers then slightly pulling oak tannins distinct elegant and remarkably vibrant this ancient canadian club is anything but tired australia only a\n"
     ]
    }
   ],
   "source": [
    "def clean_doc(text):\n",
    "\ttext = text.replace('\\\\n', ' ') # Remove new line chars, might need to make something like `\\\\r\\n`. \n",
    "\ttext = re.sub('[^a-zA-Z ]', ' ', text) # Remove numbers.\n",
    "\ttext = re.sub('[ ]{2,}', ' ', text) # Remove multiple white spaces.\n",
    "\treturn text.lower().strip() # Might need `.lstrip().rstrip()`.\n",
    "print(train['description'][0]) # Before.\n",
    "train['description'] = train['description'].apply(clean_doc) # Pandas `apply` method goes through each element.\n",
    "test['description'] = test['description'].apply(clean_doc)\n",
    "print(train['description'][0]) # After.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "(4087,)\n",
      "(1022,)\n",
      "[2881   65    0    0]\n"
     ]
    }
   ],
   "source": [
    "##\tb. SPLIT INTO FEATURE MATRIX AND TARGET VECTOR\n",
    "X_test = test['description']\n",
    "print(np.sort(np.unique(y))) # >> [0 1 2]\n",
    "print(X.shape) # >> (4087,)\n",
    "print(X_test.shape) # >> (1022,)\n",
    "print(np.histogram(y, bins=[0.5, 1.5, 2.5, 3.5, 4.5])[0]) # >> [2881   65    0    0] # Check origin to find what each unique category these are # They were types not ratings in solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## IV. PIPELINE\n",
    "## \ta. DEFINE PIPELINE COMPONENTS\n",
    "max_features = 500  # Speeds training compared to 2000\n",
    "vect = TfidfVectorizer(stop_words = 'english', max_features = max_features, ngram_range = (1, 2)) # ngrams = (unigrams(one word), bigrams(two consecutive words).\n",
    "clf = LGBMClassifier(learning_rate = 0.1, max_depth = -5, random_state = 42) # clf = classifier. LGBM = Light Gradient Boosting Classifier. Learning rate is rquired and recommended to be `0.1`.\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)]) # vect = vectorizer, and comes first. 'vect' can be any name.\n",
    "\n",
    "##\tb. HYPERPARAMETERS\n",
    "parameters = { # To specify parameter values `parameters` is a dictionary. Inside is a list of Keys and Values.'vect__max_features': ([500]), # Tried to 2000 without difference so probably good.  This is independent I think.\n",
    "\t'vect__analyzer': (['word']), # or 'characters' or other options.\n",
    "\t'vect__max_df': ([0.6]), # Independent like max features. Tried between 0.5 and 1.0. It means if words are more frequent than this you don't include them. This gets rid of common words.\n",
    "\t'clf__max_depth': ([10]), # These are the classifier parameters. GB algorithms are like RandomForest or Decision Trees, having max depth (of the tree) and...\n",
    "\t'clf__n_estimators': ([500]), # ... which is the number of trees.\n",
    "\t'clf__learning_rate': ([0.1])#, # Unique to GB. These last 3 are interconnected. Others can be trained one at a time.  Read docs to understand how to tune.\n",
    "\t# 'clf__num_leaves': ([50]), # Leaves are at the bottom of the decision tree. \n",
    "\t# 'clf__min_data_in_leaf': ([30]) # Min data points in each leaf to prevent overfitting.\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "{'clf__learning_rate': 0.1, 'clf__max_depth': 10, 'clf__n_estimators': 500, 'vect__analyzer': 'word', 'vect__max_df': 0.6}\n",
      "0.7230259257224265\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##\tc. CROSS VALIDATION\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=3, n_jobs=-1, verbose=2) # Alternatively can use RandomizedSearchCV or HalvingRandomSearchCV. This is just running Cross Validation.  Its not really a Grid Search because theres only one set of parameters for each setting above. And fitting.\n",
    "grid_search.fit(X, y)\n",
    "##\td. PRINT RESULTS\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## V. MAKE PREDICTIONS\n",
    "pred = grid_search.predict(test['description'])\n",
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred}) # Pandas DataFrame create from a dictionary technique.\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "submission.head() # Create categories and convert to integers.\n",
    "submission_number = 4\n",
    "submission.to_csv(f'submission{submission_number}.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37f98fd59b33c666e4a497b057b58a4df7f85f0f750d2f64dd4fb9023e3cf7f6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
